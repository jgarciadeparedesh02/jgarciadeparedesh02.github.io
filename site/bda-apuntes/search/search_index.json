{"config":{"lang":["es"],"separator":"[\\s\\-]+","pipeline":["stopWordFilter"]},"docs":[{"location":"","title":"Welcome to MkDocs","text":"<p>For full documentation visit mkdocs.org.</p>"},{"location":"#commands","title":"Commands","text":"<ul> <li><code>mkdocs new [dir-name]</code> - Create a new project.</li> <li><code>mkdocs serve</code> - Start the live-reloading docs server.</li> <li><code>mkdocs build</code> - Build the documentation site.</li> <li><code>mkdocs -h</code> - Print help message and exit.</li> </ul>"},{"location":"#project-layout","title":"Project layout","text":"<pre><code>mkdocs.yml    # The configuration file.\ndocs/\n    index.md  # The documentation homepage.\n    ...       # Other markdown pages, images and other files.\n</code></pre>"},{"location":"ut1-introduccion-a-hadoop/1motivacionyorigen/","title":"Big Data: Motivaci\u00f3n, Almacenamiento y Procesamiento \ud83d\ude80\ud83d\udcca","text":"<p>El t\u00e9rmino Big Data ha tomado un protagonismo inmenso en la era digital. No solo se trata de manejar grandes vol\u00famenes de datos, sino de extraer valor de ellos para tomar decisiones m\u00e1s informadas y estrat\u00e9gicas. Desde sus or\u00edgenes hasta su integraci\u00f3n con tecnolog\u00edas avanzadas como el Cloud Computing, el Big Data ha revolucionado la forma en que las organizaciones operan en todos los sectores.</p>"},{"location":"ut1-introduccion-a-hadoop/1motivacionyorigen/#motivacion-del-big-data-y-su-origen","title":"\ud83c\udf1f Motivaci\u00f3n del Big Data y su Origen","text":"<p>El Big Data surgi\u00f3 como respuesta a la necesidad de manejar cantidades masivas de datos generados por dispositivos digitales, redes sociales, sensores IoT y m\u00e1s. Empresas como Google y Facebook fueron pioneras en el uso de t\u00e9cnicas de almacenamiento y procesamiento masivo para analizar estos datos y extraer informaci\u00f3n valiosa.</p>"},{"location":"ut1-introduccion-a-hadoop/1motivacionyorigen/#por-que-es-importante-el-big-data","title":"\u00bfPor qu\u00e9 es Importante el Big Data?","text":"<ol> <li> <p>Tomar Decisiones Basadas en Datos: Las empresas ahora pueden analizar grandes conjuntos de datos para identificar patrones y tendencias, permitiendo decisiones m\u00e1s r\u00e1pidas y acertadas.</p> </li> <li> <p>Optimizaci\u00f3n de Procesos: Desde la cadena de suministro hasta el marketing, el an\u00e1lisis de Big Data permite optimizar operaciones y reducir costos.</p> </li> <li> <p>Innovaci\u00f3n y Desarrollo de Nuevos Productos: El an\u00e1lisis de datos ayuda a identificar nuevas oportunidades de mercado y a desarrollar productos que satisfagan mejor las necesidades del cliente.</p> </li> </ol>"},{"location":"ut1-introduccion-a-hadoop/1motivacionyorigen/#almacenamiento-masivo-de-datos-las-4vs-del-big-data","title":"\ud83c\udfe2 Almacenamiento Masivo de Datos: Las 4Vs del Big Data","text":"<p>El almacenamiento de datos es una piedra angular del Big Data. Para entender su complejidad, es esencial conocer las 4Vs: Volumen, Velocidad, Variedad y Valor.</p> <pre><code>graph TD\n    A[Big Data] --&gt; B[Volumen]\n    A --&gt; C[Velocidad]\n    A --&gt; D[Variedad]\n    A --&gt; E[Valor]</code></pre>"},{"location":"ut1-introduccion-a-hadoop/1motivacionyorigen/#1-volumen","title":"1. Volumen \ud83d\udce6:","text":"<p>Cantidades masivas de datos generados cada segundo, desde redes sociales hasta sensores IoT.</p>"},{"location":"ut1-introduccion-a-hadoop/1motivacionyorigen/#2-velocidad","title":"2. Velocidad \u26a1:","text":"<p>La rapidez con la que se generan y deben procesarse los datos para obtener valor en tiempo real.</p>"},{"location":"ut1-introduccion-a-hadoop/1motivacionyorigen/#3-variedad","title":"3. Variedad \ud83c\udf08:","text":"<p>Datos en m\u00faltiples formatos, tanto estructurados como no estructurados, incluyendo texto, im\u00e1genes y videos.</p>"},{"location":"ut1-introduccion-a-hadoop/1motivacionyorigen/#4-valor","title":"4. Valor \ud83d\udcb0:","text":"<p>La capacidad de transformar los datos en informaci\u00f3n \u00fatil y aplicable para la toma de decisiones.</p>"},{"location":"ut1-introduccion-a-hadoop/1motivacionyorigen/#sistemas-de-almacenamiento-de-datos","title":"\ud83d\udcc2 Sistemas de Almacenamiento de Datos","text":"<p>Los sistemas de almacenamiento deben cumplir con ciertos requisitos clave para manejar Big Data:</p> <ol> <li>Capacidad: Deben soportar el crecimiento continuo de los datos sin comprometer el rendimiento.</li> <li>Rendimiento: Capacidad de acceder y procesar datos r\u00e1pidamente.</li> <li>Fiabilidad: Asegurar que los datos est\u00e1n protegidos contra p\u00e9rdidas y fallos del sistema.</li> <li>Recuperabilidad: Facilitar la recuperaci\u00f3n de datos tras una falla o p\u00e9rdida accidental.</li> </ol>"},{"location":"ut1-introduccion-a-hadoop/1motivacionyorigen/#dispositivos-mas-usados-actualmente","title":"\ud83d\ude80 Dispositivos M\u00e1s Usados Actualmente","text":"<ol> <li> <p>Discos (HDD, SSD, RAID): </p> <ul> <li>Los discos duros HDD ofrecen almacenamiento de alta capacidad a bajo costo.</li> <li>Los SSD son m\u00e1s r\u00e1pidos y eficientes, ideales para aplicaciones que requieren alta velocidad.</li> <li>Los arreglos RAID mejoran la fiabilidad y el rendimiento al combinar varios discos en una configuraci\u00f3n redundante.</li> </ul> </li> <li> <p>Cintas Magn\u00e9ticas \ud83e\uddf2: Aunque puede parecer una tecnolog\u00eda antigua, sigue siendo utilizada para archivado de grandes vol\u00famenes de datos debido a su bajo costo.</p> </li> <li> <p>Almacenamiento en Red (NAS, SAN) \ud83c\udf10: Permite compartir almacenamiento a trav\u00e9s de una red, facilitando el acceso a datos desde m\u00faltiples dispositivos.</p> </li> <li> <p>Almacenamiento en la Nube \u2601\ufe0f: Ofrece escalabilidad, flexibilidad y recuperaci\u00f3n de datos en caso de fallos.</p> </li> </ol>"},{"location":"ut1-introduccion-a-hadoop/1motivacionyorigen/#metodos-avanzados-de-almacenamiento-clusters","title":"\ud83d\udee0\ufe0f M\u00e9todos Avanzados de Almacenamiento: Clusters","text":"<p>Los clusters y sistemas distribuidos permiten manejar datos masivos de manera m\u00e1s eficiente y segura.</p> <ul> <li> <p>Tipos de RAID: Desde RAID 0 hasta RAID 10, ofrecen diferentes niveles de redundancia y rendimiento.</p> </li> <li> <p>GlusterFS y MooseFS: Sistemas de archivos distribuidos que permiten el almacenamiento y la gesti\u00f3n eficiente de grandes vol\u00famenes de datos en clusters.</p> </li> <li> <p>CephFileSystem: Ofrece almacenamiento distribuido altamente escalable con capacidades avanzadas de recuperaci\u00f3n y auto-reparaci\u00f3n.</p> </li> <li> <p>DRBD (Distributed Replicated Block Device): Proporciona replicaci\u00f3n de datos en tiempo real, asegurando que los datos est\u00e9n siempre disponibles y sincronizados.</p> </li> </ul>"},{"location":"ut1-introduccion-a-hadoop/1motivacionyorigen/#procesamiento-de-datos-de-la-recoleccion-a-la-visualizacion","title":"\ud83d\udd0d Procesamiento de Datos: De la Recolecci\u00f3n a la Visualizaci\u00f3n","text":"<p>El procesamiento de datos en Big Data implica una serie de etapas clave para transformar los datos brutos en informaci\u00f3n valiosa.</p> <pre><code>graph LR\n    A[Recolecci\u00f3n de Datos] --&gt; B[Recopilaci\u00f3n de Datos]\n    B --&gt; C[Preprocesamiento]\n    C --&gt; D[Procesamiento]\n    D --&gt; E[Interpretaci\u00f3n]\n    E --&gt; F[Visualizaci\u00f3n]\n    F --&gt; G[An\u00e1lisis]\n    G --&gt; H[Almacenamiento]</code></pre>"},{"location":"ut1-introduccion-a-hadoop/1motivacionyorigen/#1-recoleccion-de-datos","title":"1. Recolecci\u00f3n de Datos \ud83d\udce5:","text":"<p>Recoger datos de diversas fuentes como sensores, redes sociales y bases de datos.</p>"},{"location":"ut1-introduccion-a-hadoop/1motivacionyorigen/#2-recopilacion-de-datos","title":"2. Recopilaci\u00f3n de Datos:","text":"<p>Consolidar los datos recolectados en una base central para su procesamiento.</p>"},{"location":"ut1-introduccion-a-hadoop/1motivacionyorigen/#3-preprocesamiento-o-limpieza-de-datos","title":"3. Preprocesamiento o Limpieza de Datos \ud83e\uddf9:","text":"<p>Eliminar datos redundantes, inconsistentes o incompletos para mejorar la calidad.</p>"},{"location":"ut1-introduccion-a-hadoop/1motivacionyorigen/#4-procesamiento","title":"4. Procesamiento \ud83d\udda5\ufe0f:","text":"<p>Aplicar algoritmos de an\u00e1lisis y transformaci\u00f3n para extraer patrones y conocimiento de los datos.</p>"},{"location":"ut1-introduccion-a-hadoop/1motivacionyorigen/#5-interpretacion-y-salida","title":"5. Interpretaci\u00f3n y Salida \ud83d\udcca:","text":"<p>Convertir los resultados del procesamiento en informes o visualizaciones comprensibles.</p>"},{"location":"ut1-introduccion-a-hadoop/1motivacionyorigen/#6-visualizacion-de-datos","title":"6. Visualizaci\u00f3n de Datos \ud83d\udcc8:","text":"<p>Utilizar gr\u00e1ficos, dashboards y otros medios visuales para presentar los hallazgos.</p>"},{"location":"ut1-introduccion-a-hadoop/1motivacionyorigen/#7-analisis","title":"7. An\u00e1lisis \ud83e\udde0:","text":"<p>Profundizar en los datos procesados para descubrir insights que gu\u00eden la toma de decisiones.</p>"},{"location":"ut1-introduccion-a-hadoop/1motivacionyorigen/#8-almacenamiento","title":"8. Almacenamiento:","text":"<p>Guardar los resultados de an\u00e1lisis para futuros usos o auditor\u00edas.</p>"},{"location":"ut1-introduccion-a-hadoop/1motivacionyorigen/#elementos-del-procesamiento-de-datos","title":"\u2699\ufe0f Elementos del Procesamiento de Datos","text":"<p>Los elementos clave en el procesamiento de datos incluyen servidores de procesamiento, algoritmos de an\u00e1lisis y herramientas de integraci\u00f3n que permiten a los sistemas trabajar juntos eficientemente.</p>"},{"location":"ut1-introduccion-a-hadoop/1motivacionyorigen/#mineria-de-datos","title":"Miner\u00eda de Datos \u26cf\ufe0f","text":"<p>La miner\u00eda de datos extrae patrones significativos de grandes conjuntos de datos, ayudando a predecir tendencias y comportamientos futuros.</p>"},{"location":"ut1-introduccion-a-hadoop/1motivacionyorigen/#datos-no-estructurados","title":"Datos No Estructurados \ud83d\udcd1","text":"<p>Una gran parte de los datos generados son no estructurados (e.g., texto, video, im\u00e1genes) y requieren t\u00e9cnicas avanzadas de an\u00e1lisis y procesamiento.</p>"},{"location":"ut1-introduccion-a-hadoop/1motivacionyorigen/#problemas-de-datos-no-compatibles","title":"Problemas de Datos No Compatibles \u274c","text":"<p>La heterogeneidad de los datos y la falta de est\u00e1ndares pueden dificultar su integraci\u00f3n y an\u00e1lisis, creando desaf\u00edos en la calidad y compatibilidad.</p>"},{"location":"ut1-introduccion-a-hadoop/1motivacionyorigen/#calidad-y-seguridad-de-datos","title":"Calidad y Seguridad de Datos \ud83d\udd12","text":"<p>La integridad y seguridad de los datos son fundamentales para garantizar que los an\u00e1lisis sean fiables y se mantenga la privacidad de la informaci\u00f3n.</p>"},{"location":"ut1-introduccion-a-hadoop/1motivacionyorigen/#extraccion-de-datos-completa-o-incremental","title":"Extracci\u00f3n de Datos Completa o Incremental","text":"<p>La extracci\u00f3n completa procesa todos los datos disponibles, mientras que la incremental solo analiza los cambios recientes, ahorrando tiempo y recursos.</p>"},{"location":"ut1-introduccion-a-hadoop/1motivacionyorigen/#procesamiento-en-clusters","title":"Procesamiento en Clusters \ud83d\udea6","text":"<p>El procesamiento distribuido permite que m\u00faltiples nodos trabajen en paralelo para manejar grandes vol\u00famenes de datos de manera eficiente.</p>"},{"location":"ut1-introduccion-a-hadoop/1motivacionyorigen/#analitica-de-big-data","title":"\ud83d\udcc8 Anal\u00edtica de Big Data","text":"<p>La anal\u00edtica de Big Data permite a las empresas aprovechar los datos en tiempo real para mejorar la toma de decisiones y la eficiencia operativa.</p>"},{"location":"ut1-introduccion-a-hadoop/1motivacionyorigen/#iot-internet-of-things","title":"IoT (Internet of Things) \ud83c\udf10","text":"<p>Los dispositivos IoT generan una cantidad masiva de datos que se analizan en tiempo real para optimizar operaciones como la gesti\u00f3n de flotas o el mantenimiento predictivo.</p>"},{"location":"ut1-introduccion-a-hadoop/1motivacionyorigen/#analitica-en-tiempo-real","title":"Anal\u00edtica en Tiempo Real \u23f1\ufe0f","text":"<p>Permite responder instant\u00e1neamente a eventos como transacciones financieras o cambios en la demanda del mercado, proporcionando una ventaja competitiva significativa.</p>"},{"location":"ut1-introduccion-a-hadoop/1motivacionyorigen/#big-data-y-cloud-computing","title":"\u2601\ufe0f Big Data y Cloud Computing","text":"<p>La combinaci\u00f3n de Big Data con Cloud Computing ha abierto nuevas posibilidades para las empresas, proporcionando escalabilidad, flexibilidad y reducci\u00f3n de costos.</p>"},{"location":"ut1-introduccion-a-hadoop/1motivacionyorigen/#ventajas-del-cloud-computing-para-big-data","title":"Ventajas del Cloud Computing para Big Data","text":"<ul> <li>Escalabilidad Ilimitada: Permite ajustar los recursos en funci\u00f3n de las necesidades sin comprometer el rendimiento.</li> <li>Costos Bajo Demanda: Paga solo por los recursos que utilizas, optimizando los costos operativos.</li> <li>Accesibilidad Global: Los datos y las aplicaciones pueden ser accesibles desde cualquier lugar, facilitando la colaboraci\u00f3n.</li> <li>Seguridad y Recuperaci\u00f3n: Ofrece soluciones avanzadas para la recuperaci\u00f3n de desastres y la seguridad de los datos.</li> </ul>"},{"location":"ut1-introduccion-a-hadoop/1motivacionyorigen/#conclusion","title":"\ud83d\ude80 Conclusi\u00f3n","text":"<p>El Big Data ha transformado la forma en que las organizaciones capturan, almacenan y procesan datos. Desde los or\u00edgenes del Big Data hasta las avanzadas soluciones de Cloud Computing, esta tecnolog\u00eda ha proporcionado una plataforma poderosa para la innovaci\u00f3n y la toma de decisiones estrat\u00e9gicas. La combinaci\u00f3n de almacenamiento masivo, procesamiento distribuido y an\u00e1lisis en tiempo real est\u00e1 remodelando industrias enteras y allanando el camino hacia un futuro basado en datos. \u00a1Aprovecha el poder del Big Data para llevar tu organizaci\u00f3n al siguiente nivel! \ud83d\udcca\ud83c\udf1f</p>"},{"location":"ut1-introduccion-a-hadoop/21queesapachehadoop/","title":"\u00bfQu\u00e9 es Apache Hadoop? \ud83d\ude80","text":"<p>Apache Hadoop es un marco de software de c\u00f3digo abierto dise\u00f1ado para el almacenamiento y procesamiento masivo de datos en cl\u00fasteres de computadoras. Gracias a su arquitectura distribuida, Hadoop es capaz de manejar grandes cantidades de informaci\u00f3n de manera eficiente y rentable, convirti\u00e9ndose en un pilar esencial en el mundo del Big Data.</p> <p>Hadoop no solo almacena datos, sino que tambi\u00e9n facilita su procesamiento en paralelo, lo que permite analizar informaci\u00f3n compleja r\u00e1pidamente. Su capacidad para escalar desde unos pocos servidores hasta miles lo convierte en una herramienta flexible y poderosa para empresas de todos los tama\u00f1os.</p>"},{"location":"ut1-introduccion-a-hadoop/21queesapachehadoop/#como-funciona-hadoop","title":"\ud83e\udde0 \u00bfC\u00f3mo Funciona Hadoop?","text":"<p>Hadoop se compone principalmente de cuatro m\u00f3dulos que trabajan en conjunto para proporcionar un ecosistema completo de Big Data:</p> <pre><code>graph TD;\n    A[Hadoop] --&gt; B[HDFS];\n    A --&gt; C[YARN];\n    A --&gt; D[MapReduce];\n    A --&gt; E[Hadoop Common];</code></pre> <ol> <li> <p>HDFS (Hadoop Distributed File System) \ud83d\udcc2: Almacena grandes vol\u00famenes de datos distribuidos a trav\u00e9s de m\u00faltiples nodos, garantizando alta disponibilidad y resistencia a fallos.</p> </li> <li> <p>YARN (Yet Another Resource Negotiator) \ud83c\udfaf: Act\u00faa como un administrador de recursos, asignando tareas y gestionando recursos de manera eficiente dentro del cl\u00faster.</p> </li> <li> <p>MapReduce \ud83d\udee0\ufe0f: Es el motor de procesamiento de datos que divide las tareas en subtareas m\u00e1s peque\u00f1as, permitiendo el procesamiento en paralelo de grandes conjuntos de datos.</p> </li> <li> <p>Hadoop Common \u2699\ufe0f: Proporciona las herramientas y utilidades b\u00e1sicas que soportan los dem\u00e1s m\u00f3dulos, facilitando la integraci\u00f3n y el funcionamiento del ecosistema.</p> </li> </ol>"},{"location":"ut1-introduccion-a-hadoop/21queesapachehadoop/#por-que-elegir-hadoop","title":"\ud83d\udea6 \u00bfPor Qu\u00e9 Elegir Hadoop?","text":""},{"location":"ut1-introduccion-a-hadoop/21queesapachehadoop/#1-escalabilidad-infinita","title":"1. Escalabilidad Infinita \ud83c\udfd7\ufe0f","text":"<p>Hadoop est\u00e1 dise\u00f1ado para crecer junto con tus necesidades. Desde unos pocos nodos hasta miles de m\u00e1quinas, puede manejar crecimientos exponenciales de datos sin perder rendimiento. Su arquitectura permite la adici\u00f3n de nodos sin necesidad de reconfigurar el sistema, lo que facilita la expansi\u00f3n continua.</p>"},{"location":"ut1-introduccion-a-hadoop/21queesapachehadoop/#2-rentabilidad","title":"2. Rentabilidad \ud83d\udcb0","text":"<p>El uso de hardware b\u00e1sico y de bajo costo hace que Hadoop sea una soluci\u00f3n asequible para las empresas que necesitan manejar grandes vol\u00famenes de datos. Al contrario de otros sistemas de datos que requieren hardware especializado, Hadoop se ejecuta en servidores comunes, reduciendo significativamente los costos de infraestructura.</p>"},{"location":"ut1-introduccion-a-hadoop/21queesapachehadoop/#3-flexibilidad-y-adaptabilidad","title":"3. Flexibilidad y Adaptabilidad \ud83d\udd04","text":"<p>No importa si tus datos son estructurados, no estructurados o semiestructurados; Hadoop puede almacenar y procesar cualquier tipo de informaci\u00f3n. Esto lo hace ideal para un amplio rango de aplicaciones, desde an\u00e1lisis de redes sociales hasta procesamiento de registros de sensores.</p>"},{"location":"ut1-introduccion-a-hadoop/21queesapachehadoop/#4-resistencia-a-fallos","title":"4. Resistencia a Fallos \ud83d\udd12","text":"<p>Hadoop est\u00e1 dise\u00f1ado con la seguridad en mente. Al replicar datos en varios nodos dentro del cl\u00faster, garantiza que la informaci\u00f3n est\u00e9 disponible incluso si un nodo falla, asegurando la continuidad operativa sin interrupciones.</p>"},{"location":"ut1-introduccion-a-hadoop/21queesapachehadoop/#5-procesamiento-rapido-y-paralelo","title":"5. Procesamiento R\u00e1pido y Paralelo \u26a1","text":"<p>Gracias a MapReduce, Hadoop procesa grandes vol\u00famenes de datos en paralelo, dividiendo tareas complejas en subtareas m\u00e1s peque\u00f1as. Esto ahorra tiempo y mejora la eficiencia al manejar trabajos que, de otro modo, podr\u00edan llevar horas o d\u00edas.</p>"},{"location":"ut1-introduccion-a-hadoop/21queesapachehadoop/#componentes-detallados-de-hadoop","title":"\ud83e\udde9 Componentes Detallados de Hadoop","text":""},{"location":"ut1-introduccion-a-hadoop/21queesapachehadoop/#hdfs-hadoop-distributed-file-system","title":"HDFS (Hadoop Distributed File System) \ud83d\udcc2","text":"<p>El coraz\u00f3n del almacenamiento en Hadoop es HDFS. Dise\u00f1ado para manejar archivos de gran tama\u00f1o, distribuye los datos en bloques a trav\u00e9s de m\u00faltiples nodos en el cl\u00faster. La replicaci\u00f3n de bloques asegura que, incluso si un nodo falla, los datos permanezcan accesibles.</p> <pre><code>graph TD;\n    HDFS[HDFS] --&gt;|Almacena| Datos[Datos];\n    Datos --&gt;|Divisi\u00f3n en| Bloques[Bloques];\n    Bloques --&gt;|Distribuci\u00f3n| Nodos[Nodos];\n    Nodos --&gt;|Replicaci\u00f3n| Copias[Copias de Seguridad];</code></pre> <ul> <li>Alta Disponibilidad: Los datos se replican en varios nodos, garantizando acceso continuo.</li> <li>Escalabilidad: A\u00f1adir m\u00e1s nodos incrementa autom\u00e1ticamente la capacidad de almacenamiento.</li> <li>Acceso R\u00e1pido: Dise\u00f1ado para leer y escribir datos de manera eficiente, optimizando el tiempo de respuesta.</li> </ul>"},{"location":"ut1-introduccion-a-hadoop/21queesapachehadoop/#yarn-yet-another-resource-negotiator","title":"YARN (Yet Another Resource Negotiator) \ud83c\udfaf","text":"<p>YARN es el cerebro detr\u00e1s de la asignaci\u00f3n de recursos en Hadoop. Se asegura de que cada aplicaci\u00f3n tenga acceso a los recursos necesarios para ejecutar sus tareas de manera eficiente.</p> <pre><code>// Ejemplo b\u00e1sico de c\u00f3mo YARN maneja tareas\nconst yarnTask = {\n  id: 'task123',\n  resources: {\n    cpu: 4, // N\u00facleos de CPU asignados\n    memory: '16GB' // Memoria asignada\n  },\n  execute: () =&gt; {\n    console.log('Ejecutando tarea en el cl\u00faster de Hadoop');\n  }\n};\n\nyarnTask.execute();\n</code></pre> <ul> <li>Asignaci\u00f3n Din\u00e1mica: Distribuye recursos seg\u00fan la necesidad de las aplicaciones en tiempo real.</li> <li>Optimizaci\u00f3n del Cl\u00faster: Maximiza el uso de recursos, evitando cuellos de botella.</li> </ul>"},{"location":"ut1-introduccion-a-hadoop/21queesapachehadoop/#mapreduce","title":"MapReduce \ud83d\udee0\ufe0f","text":"<p>MapReduce divide los trabajos en dos etapas: \"Map\" y \"Reduce\". En la primera, los datos se procesan y se transforman en pares clave-valor. En la segunda, estos pares se combinan para producir el resultado final.</p> <pre><code>// Ejemplo simplificado de MapReduce en JavaScript\nconst map = (data) =&gt; {\n  return data.map(item =&gt; ({ key: item, value: 1 })); // Paso de mapeo\n};\n\nconst reduce = (mappedData) =&gt; {\n  return mappedData.reduce((acc, curr) =&gt; {\n    acc[curr.key] = (acc[curr.key] || 0) + curr.value;\n    return acc;\n  }, {});\n};\n\nconst data = ['manzana', 'naranja', 'manzana', 'pera'];\nconst mapped = map(data);\nconst reduced = reduce(mapped);\n\nconsole.log(reduced); // { manzana: 2, naranja: 1, pera: 1 }\n</code></pre> <ul> <li>Procesamiento Paralelo: Divide las tareas para ejecutarlas simult\u00e1neamente, acelerando el an\u00e1lisis.</li> <li>F\u00e1cil de Escalar: A\u00f1adir m\u00e1s nodos permite manejar vol\u00famenes de datos mayores sin comprometer la velocidad.</li> </ul>"},{"location":"ut1-introduccion-a-hadoop/21queesapachehadoop/#hadoop-common","title":"Hadoop Common \u2699\ufe0f","text":"<p>Es el pegamento que mantiene todo junto, proporcionando las bibliotecas y utilidades necesarias para que los otros m\u00f3dulos funcionen correctamente. Ofrece herramientas esenciales para la configuraci\u00f3n, monitoreo y administraci\u00f3n del ecosistema Hadoop.</p>"},{"location":"ut1-introduccion-a-hadoop/21queesapachehadoop/#casos-de-uso-de-hadoop","title":"\ud83c\udf10 Casos de Uso de Hadoop","text":"<p>Hadoop ha revolucionado m\u00faltiples industrias gracias a su capacidad para manejar grandes vol\u00famenes de datos de manera eficiente. Aqu\u00ed algunos de los sectores donde Hadoop marca la diferencia:</p>"},{"location":"ut1-introduccion-a-hadoop/21queesapachehadoop/#1-finanzas-y-bancos","title":"1. Finanzas y Bancos \ud83c\udfe6","text":"<ul> <li>Detecci\u00f3n de Fraudes: Analiza patrones en tiempo real para detectar y prevenir actividades fraudulentas.</li> <li>An\u00e1lisis de Riesgos: Procesa grandes vol\u00famenes de datos financieros para identificar y gestionar riesgos.</li> </ul>"},{"location":"ut1-introduccion-a-hadoop/21queesapachehadoop/#2-salud","title":"2. Salud \ud83c\udfe5","text":"<ul> <li>Gen\u00f3mica: Procesa datos de secuenciaci\u00f3n gen\u00e9tica para avanzar en la medicina personalizada.</li> <li>An\u00e1lisis de Im\u00e1genes M\u00e9dicas: Maneja grandes vol\u00famenes de im\u00e1genes para mejorar diagn\u00f3sticos y tratamientos.</li> </ul>"},{"location":"ut1-introduccion-a-hadoop/21queesapachehadoop/#3-telecomunicaciones","title":"3. Telecomunicaciones \ud83d\udce1","text":"<ul> <li>An\u00e1lisis de Redes: Monitorea y optimiza el rendimiento de las redes en tiempo real.</li> <li>Modelos Predictivos: Utiliza datos hist\u00f3ricos para prever fallos y optimizar el servicio al cliente.</li> </ul>"},{"location":"ut1-introduccion-a-hadoop/21queesapachehadoop/#4-retail-y-e-commerce","title":"4. Retail y E-commerce \ud83d\uded2","text":"<ul> <li>An\u00e1lisis del Comportamiento del Cliente: Utiliza datos de navegaci\u00f3n y compra para personalizar ofertas.</li> <li>Gesti\u00f3n de Inventarios: Optimiza la cadena de suministro basada en patrones de compra y demanda.</li> </ul>"},{"location":"ut1-introduccion-a-hadoop/21queesapachehadoop/#comienza-con-hadoop-hoy","title":"\ud83d\ude80 \u00a1Comienza con Hadoop Hoy!","text":"<p>Si tu objetivo es aprovechar al m\u00e1ximo tus datos y llevar tus capacidades anal\u00edticas al siguiente nivel, Hadoop es la herramienta que necesitas. Con su escalabilidad, flexibilidad y eficiencia, es una soluci\u00f3n inigualable para los desaf\u00edos del Big Data en el mundo moderno. Empieza a explorar las posibilidades que Hadoop tiene para ofrecer y desbloquea el verdadero potencial de tus datos.</p>"},{"location":"ut1-introduccion-a-hadoop/21queesapachehadoop/#ejemplo-completo-de-integracion-en-javascript","title":"\ud83d\udee0\ufe0f Ejemplo Completo de Integraci\u00f3n en JavaScript:","text":"<pre><code>const hdfs = require('hdfs'); // Biblioteca para interactuar con HDFS\n\n// Conectar a HDFS\nconst client = hdfs({\n  protocol: 'http', // Protocolo de conexi\u00f3n\n  hostname: 'localhost', // Host de Hadoop\n  port: 9870 // Puerto de HDFS\n});\n\n// Crear un nuevo archivo en HDFS\nclient.createFile('/user/data.txt', 'Hola, Hadoop!', (err) =&gt; {\n  if (err) {\n    console.error('Error al crear archivo:', err);\n  } else {\n    console.log('Archivo creado exitosamente!');\n  }\n});\n\n// Leer archivos en un directorio\nclient.listStatus('/user/', (err, files) =&gt; {\n  if (err) {\n    console.error('Error al listar archivos:', err);\n  } else {\n    console.log('Archivos en el directorio:', files);\n  }\n});\n</code></pre>"},{"location":"ut1-introduccion-a-hadoop/21queesapachehadoop/#conclusion","title":"\ud83c\udf10 Conclusi\u00f3n","text":"<p>Apache Hadoop no es solo una tecnolog\u00eda; es una revoluci\u00f3n en la forma en que manejamos y procesamos los datos.</p> <p>Desde peque\u00f1as startups hasta grandes corporaciones, la adopci\u00f3n de Hadoop ha transformado la capacidad de las organizaciones para tomar decisiones basadas en datos. \u00a1Es hora de sumergirse en el mundo del Big Data con Hadoop y descubrir lo que puedes lograr!</p>"},{"location":"ut1-introduccion-a-hadoop/22ecosistemahadoopydistribuciones/","title":"Ecosistema Hadoop y Distribuciones \ud83c\udf10\ud83d\ude80","text":"<p>El ecosistema Hadoop ha revolucionado la forma en que las organizaciones manejan y procesan datos a gran escala. Hadoop no es solo un software; es un ecosistema completo de herramientas y tecnolog\u00edas que trabajan juntas para resolver los desaf\u00edos del Big Data. A medida que el volumen, la variedad y la velocidad de los datos contin\u00faan creciendo, el ecosistema Hadoop se expande para incluir m\u00faltiples componentes y distribuciones dise\u00f1adas para aprovechar al m\u00e1ximo esta revoluci\u00f3n de datos.</p>"},{"location":"ut1-introduccion-a-hadoop/22ecosistemahadoopydistribuciones/#que-es-el-ecosistema-hadoop","title":"\ud83e\udde0 \u00bfQu\u00e9 es el Ecosistema Hadoop?","text":"<p>El ecosistema Hadoop es una colecci\u00f3n de proyectos y herramientas que interact\u00faan entre s\u00ed para proporcionar una plataforma integral para el almacenamiento, procesamiento y an\u00e1lisis de grandes vol\u00famenes de datos. Este ecosistema incluye componentes para la ingesti\u00f3n de datos, el procesamiento en tiempo real, el an\u00e1lisis avanzado y la gesti\u00f3n de recursos.</p> <pre><code>graph LR\n    A[Hadoop Ecosystem] --&gt; B[HDFS]\n    A --&gt; C[YARN]\n    A --&gt; D[MapReduce]\n    A --&gt; E[Spark]\n    A --&gt; F[Hive]\n    A --&gt; G[HBase]\n    A --&gt; H[Pig]\n    A --&gt; I[Oozie]\n    A --&gt; J[Sqoop]\n    A --&gt; K[Flume]</code></pre>"},{"location":"ut1-introduccion-a-hadoop/22ecosistemahadoopydistribuciones/#componentes-clave-del-ecosistema-hadoop","title":"Componentes Clave del Ecosistema Hadoop \ud83d\udee0\ufe0f","text":"<ol> <li> <p>HDFS (Hadoop Distributed File System) \ud83d\udcc2: El sistema de archivos distribuido que almacena grandes vol\u00famenes de datos de manera eficiente y segura.</p> </li> <li> <p>YARN (Yet Another Resource Negotiator) \ud83c\udfaf: Gestor de recursos que asigna y administra las tareas dentro del cl\u00faster Hadoop.</p> </li> <li> <p>MapReduce \ud83d\udee0\ufe0f: Modelo de programaci\u00f3n que permite el procesamiento paralelo de datos en un entorno distribuido.</p> </li> <li> <p>Apache Spark \u26a1: Motor de procesamiento r\u00e1pido y en memoria que ofrece una alternativa m\u00e1s \u00e1gil a MapReduce para el an\u00e1lisis de datos en tiempo real.</p> </li> <li> <p>Apache Hive \ud83d\udc1d: Herramienta que facilita la consulta y el an\u00e1lisis de datos almacenados en HDFS utilizando un lenguaje similar a SQL, conocido como HiveQL.</p> </li> <li> <p>Apache HBase \ud83d\udcca: Base de datos NoSQL de alto rendimiento que proporciona acceso en tiempo real a grandes vol\u00famenes de datos distribuidos.</p> </li> <li> <p>Apache Pig \ud83d\udc37: Lenguaje de alto nivel para el procesamiento de grandes conjuntos de datos que simplifica la escritura de scripts complejos en comparaci\u00f3n con MapReduce.</p> </li> <li> <p>Apache Oozie \ud83d\udcc5: Coordinador de flujos de trabajo que permite programar y gestionar trabajos en Hadoop.</p> </li> <li> <p>Apache Sqoop \ud83d\udd04: Herramienta que facilita la transferencia de datos entre Hadoop y bases de datos relacionales.</p> </li> <li> <p>Apache Flume \ud83d\udce5: Sistema de ingesti\u00f3n de datos que permite recopilar, agregar y mover grandes cantidades de datos de eventos a Hadoop.</p> </li> </ol>"},{"location":"ut1-introduccion-a-hadoop/22ecosistemahadoopydistribuciones/#distribuciones-populares-de-hadoop","title":"\ud83c\udf10 Distribuciones Populares de Hadoop","text":"<p>Las distribuciones de Hadoop son paquetes que integran el ecosistema de herramientas Hadoop con caracter\u00edsticas adicionales de administraci\u00f3n y soporte. Estas distribuciones est\u00e1n dise\u00f1adas para simplificar la implementaci\u00f3n, configuraci\u00f3n y mantenimiento de cl\u00fasteres Hadoop. Aqu\u00ed te presentamos algunas de las m\u00e1s populares:</p>"},{"location":"ut1-introduccion-a-hadoop/22ecosistemahadoopydistribuciones/#1-cloudera-distribution-for-hadoop-cdh","title":"1. Cloudera Distribution for Hadoop (CDH) \ud83c\udfe2","text":"<p>Cloudera es una de las distribuciones comerciales m\u00e1s reconocidas de Hadoop. Ofrece una versi\u00f3n completa del ecosistema Hadoop con herramientas adicionales para la gesti\u00f3n, seguridad y an\u00e1lisis de datos.</p> <ul> <li>Gesti\u00f3n Simplificada: Cloudera Manager permite gestionar y monitorear el cl\u00faster de forma centralizada.</li> <li>Seguridad Mejorada: Ofrece encriptaci\u00f3n de datos y autenticaci\u00f3n avanzada.</li> <li>Optimizaci\u00f3n de Desempe\u00f1o: Ajustes autom\u00e1ticos que mejoran la eficiencia de las tareas.</li> </ul> <pre><code>// Ejemplo de conexi\u00f3n a un cl\u00faster de Hadoop usando Cloudera\nconst cloudera = require('cloudera-api');\n\n// Conectar al cl\u00faster de Cloudera\nconst client = new cloudera.Cluster({\n  hostname: 'cloudera-cluster.local',\n  username: 'admin',\n  password: 'password'\n});\n\nclient.getStatus((err, status) =&gt; {\n  if (err) {\n    console.error('Error conectando al cl\u00faster:', err);\n  } else {\n    console.log('Estado del cl\u00faster:', status);\n  }\n});\n</code></pre>"},{"location":"ut1-introduccion-a-hadoop/22ecosistemahadoopydistribuciones/#2-hortonworks-data-platform-hdp","title":"2. Hortonworks Data Platform (HDP) \ud83d\udc18","text":"<p>Hortonworks, ahora parte de Cloudera, ofrece una distribuci\u00f3n de Hadoop completamente de c\u00f3digo abierto. HDP se enfoca en la integraci\u00f3n de datos y proporciona un s\u00f3lido conjunto de herramientas para el an\u00e1lisis y la gesti\u00f3n de datos.</p> <ul> <li>Soporte 100% Open Source: Fomenta la innovaci\u00f3n y permite la personalizaci\u00f3n completa de la plataforma.</li> <li>Integraci\u00f3n con la Nube: Compatible con implementaciones en la nube y en entornos h\u00edbridos.</li> <li>Simplificaci\u00f3n de Operaciones: Herramientas para la automatizaci\u00f3n de flujos de trabajo y la gesti\u00f3n de datos.</li> </ul>"},{"location":"ut1-introduccion-a-hadoop/22ecosistemahadoopydistribuciones/#3-mapr","title":"3. MapR \ud83c\udf32","text":"<p>MapR destaca por su arquitectura \u00fanica que combina Hadoop con un sistema de archivos distribuido patentado y una base de datos NoSQL integrada. Ofrece una alta disponibilidad y rendimiento superior en comparaci\u00f3n con otras distribuciones.</p> <ul> <li>MapR XD y MapR DB: Proporcionan almacenamiento y gesti\u00f3n de datos avanzados con capacidades empresariales.</li> <li>Soporte de Contenedores y Microservicios: Compatible con Kubernetes para la implementaci\u00f3n de aplicaciones modernas.</li> <li>Procesamiento en Tiempo Real: Capacidades para an\u00e1lisis de flujos de datos en tiempo real.</li> </ul> <pre><code>// Ejemplo de integraci\u00f3n con MapR usando JavaScript\nconst mapr = require('mapr-streams');\n\n// Configuraci\u00f3n de una conexi\u00f3n de flujo de datos en tiempo real\nconst stream = mapr.createStream('/path/to/stream');\n\nstream.on('data', (message) =&gt; {\n  console.log('Mensaje recibido:', message.value.toString());\n});\n\nstream.write({ key: 'sensor1', value: 'temperatura: 22\u00b0C' });\n</code></pre>"},{"location":"ut1-introduccion-a-hadoop/22ecosistemahadoopydistribuciones/#4-amazon-emr-elastic-mapreduce","title":"4. Amazon EMR (Elastic MapReduce) \u2601\ufe0f","text":"<p>Amazon EMR es la distribuci\u00f3n basada en la nube de Hadoop ofrecida por AWS. Permite escalar f\u00e1cilmente el cl\u00faster y ajustar los recursos seg\u00fan la demanda de procesamiento de datos.</p> <ul> <li>Escalabilidad Autom\u00e1tica: Ajusta la capacidad del cl\u00faster en funci\u00f3n de la carga de trabajo.</li> <li>Integraci\u00f3n con Servicios AWS: F\u00e1cil integraci\u00f3n con S3, Redshift y otras soluciones de AWS.</li> <li>Costos Bajo Demanda: Paga solo por lo que usas, optimizando los costos operativos.</li> </ul>"},{"location":"ut1-introduccion-a-hadoop/22ecosistemahadoopydistribuciones/#casos-de-uso-del-ecosistema-hadoop","title":"\ud83d\udea6 Casos de Uso del Ecosistema Hadoop","text":"<p>El ecosistema Hadoop no solo almacena datos; lo transforma en valor accionable. A continuaci\u00f3n, se presentan algunos casos de uso donde las empresas utilizan Hadoop y sus herramientas para generar impacto:</p>"},{"location":"ut1-introduccion-a-hadoop/22ecosistemahadoopydistribuciones/#1-analisis-de-redes-sociales","title":"1. An\u00e1lisis de Redes Sociales \ud83d\udde8\ufe0f","text":"<p>Las empresas analizan millones de interacciones en redes sociales para entender las tendencias del mercado y la opini\u00f3n del cliente. Herramientas como Spark y Hive se utilizan para procesar estos datos r\u00e1pidamente.</p>"},{"location":"ut1-introduccion-a-hadoop/22ecosistemahadoopydistribuciones/#2-recomendacion-de-productos","title":"2. Recomendaci\u00f3n de Productos \ud83d\udecd\ufe0f","text":"<p>Las plataformas de e-commerce utilizan algoritmos de aprendizaje autom\u00e1tico en Hadoop para analizar el comportamiento del usuario y recomendar productos personalizados en tiempo real.</p> <pre><code>// Ejemplo de recomendaci\u00f3n de productos usando Spark y JavaScript\nconst spark = require('apache-spark');\n\n// Crear un modelo de recomendaci\u00f3n basado en el historial de compras del usuario\nconst recommendations = spark.mllib.recommendation.ALS.train(usersPurchases, 10, 0.01);\n\nrecommendations.predict(user, (err, products) =&gt; {\n  if (err) {\n    console.error('Error generando recomendaciones:', err);\n  } else {\n    console.log('Productos recomendados:', products);\n  }\n});\n</code></pre>"},{"location":"ut1-introduccion-a-hadoop/22ecosistemahadoopydistribuciones/#3-prevencion-de-fraudes-financieros","title":"3. Prevenci\u00f3n de Fraudes Financieros \ud83c\udfe6","text":"<p>Bancos y aseguradoras usan Hadoop para analizar transacciones en tiempo real y detectar patrones sospechosos. Hadoop permite combinar m\u00faltiples fuentes de datos para una detecci\u00f3n de fraudes m\u00e1s precisa y r\u00e1pida.</p>"},{"location":"ut1-introduccion-a-hadoop/22ecosistemahadoopydistribuciones/#4-monitoreo-de-infraestructuras","title":"4. Monitoreo de Infraestructuras \ud83d\udce1","text":"<p>Las empresas de telecomunicaciones utilizan el ecosistema Hadoop para monitorear sus infraestructuras de red, detectando fallos y optimizando el rendimiento en tiempo real.</p>"},{"location":"ut1-introduccion-a-hadoop/22ecosistemahadoopydistribuciones/#ejemplo-completo-de-integracion-del-ecosistema-hadoop-en-javascript","title":"\ud83d\udee0\ufe0f Ejemplo Completo de Integraci\u00f3n del Ecosistema Hadoop en JavaScript","text":"<p>Para entender c\u00f3mo funciona el ecosistema Hadoop en la pr\u00e1ctica, consideremos un ejemplo completo que integra varios componentes:</p> <pre><code>const hdfs = require('hdfs');\nconst spark = require('apache-spark');\nconst hive = require('hive-client');\n\n// Configuraci\u00f3n de HDFS\nconst hdfsClient = hdfs({\n  protocol: 'http',\n  hostname: 'localhost',\n  port: 9870\n});\n\n// Subir datos a HDFS\nhdfsClient.createFile('/user/data.txt', 'Datos para an\u00e1lisis', (err) =&gt; {\n  if (err) {\n    console.error('Error al subir archivo:', err);\n  } else {\n    console.log('Archivo subido a HDFS correctamente.');\n  }\n});\n\n// Consultar datos en Hive\nconst hiveClient = hive.createClient({ host: 'localhost', port: 10000 });\n\nhiveClient.connect().then(() =&gt; {\n  hiveClient.query('SELECT * FROM logs WHERE event=\"error\";', (err, results) =&gt; {\n    if (err) {\n      console.error('Error en la consulta Hive:', err);\n    } else {\n\n\n console.log('Resultados de la consulta:', results);\n    }\n  });\n});\n\n// Procesar datos con Spark\nspark.session.builder().getOrCreate().then(session =&gt; {\n  const dataFrame = session.read().format('csv').load('/user/data.txt');\n\n  dataFrame.filter(dataFrame.col('event').equalTo('error'))\n    .show()\n    .then(() =&gt; session.stop());\n});\n</code></pre>"},{"location":"ut1-introduccion-a-hadoop/22ecosistemahadoopydistribuciones/#conclusion","title":"\ud83c\udf1f Conclusi\u00f3n","text":"<p>El ecosistema Hadoop y sus diversas distribuciones son fundamentales para cualquier estrategia de Big Data moderna. Ofrecen una soluci\u00f3n integral para almacenar, procesar y analizar datos a gran escala, permitiendo a las empresas tomar decisiones informadas basadas en datos. Con la flexibilidad para manejar todo tipo de datos y la capacidad de escalar a cualquier tama\u00f1o de cl\u00faster, Hadoop contin\u00faa liderando la transformaci\u00f3n digital en todo el mundo. \u00a1Explora el poder del ecosistema Hadoop y descubre c\u00f3mo puede revolucionar tu gesti\u00f3n de datos! \ud83d\ude80\ud83d\udcca</p>"},{"location":"ut1-introduccion-a-hadoop/23arquitectura/","title":"Arquitectura de Hadoop: Desentra\u00f1ando la Potencia del Big Data \ud83d\ude80\ud83e\udde0","text":"<p>Apache Hadoop es una plataforma robusta de c\u00f3digo abierto dise\u00f1ada para almacenar y procesar grandes vol\u00famenes de datos de manera eficiente y escalable. Pero \u00bfqu\u00e9 hace que Hadoop sea tan poderoso? La respuesta radica en su arquitectura distribuida, que permite procesar datos a trav\u00e9s de m\u00faltiples nodos de manera paralela. En este art\u00edculo, exploraremos en detalle la arquitectura de Hadoop, desglosando sus componentes y c\u00f3mo trabajan juntos para hacer del Big Data una realidad accesible.</p>"},{"location":"ut1-introduccion-a-hadoop/23arquitectura/#componentes-principales-de-la-arquitectura-de-hadoop","title":"\ud83e\udde9 Componentes Principales de la Arquitectura de Hadoop","text":"<p>La arquitectura de Hadoop se compone de varios m\u00f3dulos que colaboran para ofrecer un entorno completo de almacenamiento y procesamiento de datos. Los componentes clave son:</p> <pre><code>graph TD\n    A[Arquitectura de Hadoop] --&gt; B[HDFS]\n    A --&gt; C[YARN]\n    A --&gt; D[MapReduce]\n    A --&gt; E[Hadoop Common]\n    A --&gt; F[Componentes de Integraci\u00f3n]</code></pre>"},{"location":"ut1-introduccion-a-hadoop/23arquitectura/#1-hdfs-hadoop-distributed-file-system","title":"1. HDFS (Hadoop Distributed File System) \ud83d\udcc2","text":"<p>HDFS es el sistema de archivos distribuido de Hadoop, dise\u00f1ado para almacenar datos de manera segura y eficiente en grandes cl\u00fasteres. Se encarga de dividir los archivos grandes en bloques y distribuirlos a trav\u00e9s de diferentes nodos en el cl\u00faster.</p> <pre><code>graph TD\n    HDFS[HDFS] --&gt;|Divide Archivos en| Bloques[Bloques]\n    Bloques --&gt;|Distribuye en| Nodos[Nodos]\n    Nodos --&gt;|Copia y Replicaci\u00f3n| Copias[Copias de Seguridad]</code></pre>"},{"location":"ut1-introduccion-a-hadoop/23arquitectura/#caracteristicas-de-hdfs","title":"Caracter\u00edsticas de HDFS:","text":"<ul> <li>Alta Disponibilidad: Al replicar los bloques de datos en varios nodos, asegura que los datos est\u00e9n siempre disponibles, incluso si uno de los nodos falla.</li> <li>Escalabilidad: A\u00f1adir nuevos nodos al cl\u00faster incrementa autom\u00e1ticamente la capacidad de almacenamiento.</li> <li>Tolerancia a Fallos: Dise\u00f1ado para detectar y recuperarse autom\u00e1ticamente de fallos de hardware y software.</li> </ul>"},{"location":"ut1-introduccion-a-hadoop/23arquitectura/#2-yarn-yet-another-resource-negotiator","title":"2. YARN (Yet Another Resource Negotiator) \ud83c\udfaf","text":"<p>YARN act\u00faa como el gestor de recursos de Hadoop. Asigna recursos de procesamiento a las aplicaciones y coordina la ejecuci\u00f3n de tareas en el cl\u00faster, asegurando que los trabajos se completen de manera eficiente.</p> <pre><code>graph TD\n    YARN[YARN] --&gt;|Gesti\u00f3n de Recursos| Asignaci\u00f3n[Asignaci\u00f3n de Recursos]\n    YARN --&gt;|Ejecuci\u00f3n de Tareas| Tareas[Tareas del Cl\u00faster]\n    Tareas --&gt;|Optimizaci\u00f3n| Eficiencia[Eficiencia del Cl\u00faster]</code></pre>"},{"location":"ut1-introduccion-a-hadoop/23arquitectura/#caracteristicas-de-yarn","title":"Caracter\u00edsticas de YARN:","text":"<ul> <li>Asignaci\u00f3n Din\u00e1mica de Recursos: Distribuye recursos seg\u00fan las necesidades de las aplicaciones en tiempo real, optimizando el uso del cl\u00faster.</li> <li>Seguridad y Control: Ofrece control granular sobre la ejecuci\u00f3n de tareas, garantizando la seguridad y estabilidad del sistema.</li> <li>Escalabilidad: Permite la expansi\u00f3n del cl\u00faster sin necesidad de reconfiguraciones complejas.</li> </ul>"},{"location":"ut1-introduccion-a-hadoop/23arquitectura/#3-mapreduce","title":"3. MapReduce \ud83d\udee0\ufe0f","text":"<p>MapReduce es el modelo de programaci\u00f3n de Hadoop que permite el procesamiento paralelo de grandes vol\u00famenes de datos. Consiste en dos fases principales: Map y Reduce.</p> <pre><code>graph TD\n    A[MapReduce] --&gt; B[Map]\n    A --&gt; C[Reduce]\n    B --&gt; D[Procesa Datos en Pares Clave-Valor]\n    C --&gt; E[Combina y Reduce Resultados]</code></pre> <ul> <li>Map: Toma los datos de entrada y los procesa en pares clave-valor.</li> <li>Reduce: Combina estos pares para generar un resultado final.</li> </ul>"},{"location":"ut1-introduccion-a-hadoop/23arquitectura/#ejemplo-de-mapreduce-en-javascript","title":"Ejemplo de MapReduce en JavaScript:","text":"<pre><code>// Ejemplo de MapReduce para contar palabras\nconst map = (text) =&gt; {\n  return text.split(' ').map(word =&gt; ({ key: word, value: 1 }));\n};\n\nconst reduce = (mappedData) =&gt; {\n  return mappedData.reduce((acc, curr) =&gt; {\n    acc[curr.key] = (acc[curr.key] || 0) + curr.value;\n    return acc;\n  }, {});\n};\n\nconst data = \"Hadoop es incre\u00edble, Hadoop es poderoso\";\nconst mapped = map(data);\nconst reduced = reduce(mapped);\n\nconsole.log(reduced); // { Hadoop: 2, es: 2, incre\u00edble: 1, poderoso: 1 }\n</code></pre>"},{"location":"ut1-introduccion-a-hadoop/23arquitectura/#4-hadoop-common","title":"4. Hadoop Common \u2699\ufe0f","text":"<p>Hadoop Common proporciona las bibliotecas y utilidades necesarias que soportan los otros m\u00f3dulos de Hadoop, asegurando la integraci\u00f3n y el funcionamiento adecuado de todo el ecosistema.</p> <ul> <li>Funciones B\u00e1sicas: Ofrece soporte para la gesti\u00f3n de configuraci\u00f3n, registro y acceso remoto.</li> <li>Soporte Multiplataforma: Compatible con diferentes sistemas operativos, lo que facilita su implementaci\u00f3n en cualquier entorno.</li> </ul>"},{"location":"ut1-introduccion-a-hadoop/23arquitectura/#5-componentes-de-integracion","title":"5. Componentes de Integraci\u00f3n \ud83d\udd0c","text":"<p>Hadoop no funciona en solitario. Se integra con varias herramientas y tecnolog\u00edas para ampliar sus capacidades y proporcionar un entorno m\u00e1s completo para la gesti\u00f3n de datos:</p> <pre><code>graph TD\n    Hadoop[Hadoop] --&gt; Spark[Spark]\n    Hadoop --&gt; Hive[Hive]\n    Hadoop --&gt; HBase[HBase]\n    Hadoop --&gt; Pig[Pig]\n    Hadoop --&gt; Sqoop[Sqoop]\n    Hadoop --&gt; Flume[Flume]</code></pre> <ul> <li>Apache Spark \u26a1: Ofrece procesamiento en memoria, lo que acelera las tareas de an\u00e1lisis en comparaci\u00f3n con MapReduce.</li> <li>Apache Hive \ud83d\udc1d: Permite consultas SQL sobre datos almacenados en HDFS, facilitando el an\u00e1lisis de datos.</li> <li>Apache HBase \ud83d\udcca: Proporciona acceso en tiempo real a grandes vol\u00famenes de datos distribuidos, ideal para aplicaciones que requieren baja latencia.</li> <li>Apache Pig \ud83d\udc37: Un lenguaje de alto nivel para escribir scripts que procesen grandes conjuntos de datos de manera m\u00e1s simple que MapReduce.</li> <li>Apache Sqoop \ud83d\udd04: Facilita la transferencia de datos entre Hadoop y bases de datos relacionales.</li> <li>Apache Flume \ud83d\udce5: Recoge, agrega y mueve grandes cantidades de datos de eventos a Hadoop.</li> </ul>"},{"location":"ut1-introduccion-a-hadoop/23arquitectura/#como-trabajan-juntos-los-componentes-de-hadoop","title":"\ud83d\udea6 \u00bfC\u00f3mo Trabajan Juntos los Componentes de Hadoop?","text":"<p>La arquitectura de Hadoop se basa en la sinergia de sus componentes. Cada m\u00f3dulo desempe\u00f1a un papel esencial en el procesamiento y almacenamiento de datos a gran escala, trabajando de manera conjunta para ofrecer un entorno completo y robusto.</p> <ol> <li> <p>Ingesti\u00f3n de Datos: Los datos se recopilan mediante herramientas como Flume o Sqoop y se almacenan en HDFS.</p> </li> <li> <p>Gesti\u00f3n de Recursos: YARN administra los recursos del cl\u00faster, asegurando que las tareas se distribuyan de manera eficiente.</p> </li> <li> <p>Procesamiento de Datos: Se realiza mediante MapReduce, Spark, Pig o Hive, dependiendo del tipo de an\u00e1lisis requerido.</p> </li> <li> <p>Acceso y An\u00e1lisis: Hive proporciona un lenguaje similar a SQL para consultar y analizar datos, mientras que HBase permite el acceso en tiempo real.</p> </li> <li> <p>Automatizaci\u00f3n de Flujos de Trabajo: Oozie coordina la ejecuci\u00f3n de trabajos y la automatizaci\u00f3n de tareas repetitivas en el cl\u00faster.</p> </li> </ol>"},{"location":"ut1-introduccion-a-hadoop/23arquitectura/#ejemplo-completo-de-integracion-de-la-arquitectura-hadoop-en-javascript","title":"\ud83c\udf1f Ejemplo Completo de Integraci\u00f3n de la Arquitectura Hadoop en JavaScript","text":"<p>Para ilustrar c\u00f3mo todos estos componentes trabajan en conjunto, veamos un ejemplo pr\u00e1ctico de integraci\u00f3n utilizando JavaScript:</p> <pre><code>const hdfs = require('hdfs'); // Interacci\u00f3n con HDFS\nconst yarn = require('yarn-client'); // Gesti\u00f3n de tareas en el cl\u00faster\nconst hive = require('hive-client'); // Consultas en Hive\n\n// Conectar a HDFS\nconst hdfsClient = hdfs({\n  protocol: 'http',\n  hostname: 'localhost',\n  port: 9870\n});\n\n// Subir datos a HDFS\nhdfsClient.createFile('/user/data.txt', 'Hadoop es un sistema distribuido', (err) =&gt; {\n  if (err) {\n    console.error('Error al crear archivo en HDFS:', err);\n  } else {\n    console.log('Archivo creado en HDFS.');\n  }\n});\n\n// Ejecutar tarea con YARN\nconst yarnClient = new yarn.Client();\nyarnClient.submitJob('analyze-data', '/user/data.txt', (err) =&gt; {\n  if (err) {\n    console.error('Error ejecutando trabajo en YARN:', err);\n  } else {\n    console.log('Trabajo completado en YARN.');\n  }\n});\n\n// Consultar resultados en Hive\nconst hiveClient = hive.createClient({ host: 'localhost', port: 10000 });\n\nhiveClient.connect().then(() =&gt; {\n  hiveClient.query('SELECT * FROM logs WHERE event=\"Hadoop\";', (err, results) =&gt; {\n    if (err) {\n      console.error('Error en la consulta Hive:', err);\n    } else {\n      console.log('Resultados de la consulta Hive:', results);\n    }\n  });\n});\n</code></pre>"},{"location":"ut1-introduccion-a-hadoop/23arquitectura/#conclusion","title":"\ud83d\ude80 Conclusi\u00f3n","text":"<p>La arquitectura de Hadoop es un ejemplo brillante de c\u00f3mo los sistemas distribuidos pueden transformar la manera en que manejamos y analizamos datos masivos. Con una combinaci\u00f3n de almacenamiento robusto, gesti\u00f3n eficiente de recursos y capacidades avanzadas de procesamiento, Hadoop se ha convertido en la columna vertebral del Big Data moderno. Ya sea que est\u00e9s trabajando en an\u00e1lisis de datos, modelado predictivo o simplemente necesites un sistema escalable y resistente, la arquitectura de Hadoop proporciona las herramientas necesarias para desbloquear el verdadero potencial de tus datos. \ud83c\udf10</p>"},{"location":"ut1-introduccion-a-hadoop/2apachehadoopaaltonivel/","title":"Apache Hadoop a Alto Nivel","text":""},{"location":"ut1-introduccion-a-hadoop/2apachehadoopaaltonivel/#introduccion-a-apache-hadoop","title":"\ud83e\uddd1\u200d\ud83d\udcbb Introducci\u00f3n a Apache Hadoop","text":"<p>Apache Hadoop es una de las tecnolog\u00edas m\u00e1s influyentes en el campo del Big Data. Esta plataforma de c\u00f3digo abierto permite almacenar y procesar grandes vol\u00famenes de datos de manera eficiente, gracias a su arquitectura distribuida y escalable.</p> <pre><code>graph LR\nA[Apache Hadoop] --&gt; B[HDFS]\nA --&gt; C[YARN]\nA --&gt; D[MapReduce]\nA --&gt; E[HBase]\nA --&gt; F[Hive]</code></pre>"},{"location":"ut1-introduccion-a-hadoop/2apachehadoopaaltonivel/#componentes-principales","title":"\ud83d\udcca Componentes Principales","text":"<ol> <li>HDFS (Hadoop Distributed File System): Sistema de archivos distribuido que permite almacenar grandes vol\u00famenes de datos de forma redundante, asegurando su disponibilidad y durabilidad.</li> </ol> <pre><code># Ejemplo de almacenamiento en HDFS\nhadoop fs -put localfile.txt /hadoop/path/\n</code></pre> <ol> <li> <p>YARN (Yet Another Resource Negotiator): Gestor de recursos que asigna tareas a los nodos disponibles en el cl\u00faster, optimizando el uso de la infraestructura.</p> </li> <li> <p>MapReduce: Modelo de programaci\u00f3n para procesar y generar grandes conjuntos de datos de manera paralela.</p> </li> </ol> <pre><code># Pseudoc\u00f3digo de MapReduce\nmap(String key, String value):\n    emit(key, value_length)\n\nreduce(String key, Iterator values):\n    sum = 0\n    for value in values:\n        sum += value\n    emit(key, sum)\n</code></pre> <ol> <li> <p>HBase: Base de datos NoSQL que permite acceso en tiempo real a grandes vol\u00famenes de datos almacenados en HDFS.</p> </li> <li> <p>Hive: Herramienta que proporciona una interfaz SQL para consultar y manejar datos almacenados en Hadoop.</p> </li> </ol>"},{"location":"ut1-introduccion-a-hadoop/2apachehadoopaaltonivel/#beneficios-de-apache-hadoop","title":"\ud83d\ude80 Beneficios de Apache Hadoop","text":"<ul> <li>Escalabilidad Horizontal: Permite a\u00f1adir m\u00e1s nodos al cl\u00faster para aumentar la capacidad de procesamiento y almacenamiento.</li> <li>Alta Disponibilidad: Asegura la replicaci\u00f3n de datos y el balanceo de carga entre los nodos.</li> <li>Costo Efectivo: Utiliza hardware com\u00fan, reduciendo significativamente los costos en comparaci\u00f3n con soluciones propietarias.</li> </ul>"},{"location":"ut1-introduccion-a-hadoop/2apachehadoopaaltonivel/#aplicaciones-comunes","title":"\ud83c\udfaf Aplicaciones Comunes","text":"<ul> <li>An\u00e1lisis de Datos a Gran Escala: Utilizado en sectores como finanzas, salud y marketing para analizar grandes vol\u00famenes de datos de manera eficiente.</li> <li>Procesamiento de Log Files: Herramienta clave para analizar logs de servidores web y obtener insights en tiempo real.</li> <li>Machine Learning: Facilita la construcci\u00f3n de modelos a partir de conjuntos de datos masivos.</li> </ul>"},{"location":"ut1-introduccion-a-hadoop/2apachehadoopaaltonivel/#conclusion","title":"\ud83c\udf10 Conclusi\u00f3n","text":"<p>Apache Hadoop ha revolucionado la forma en que las empresas manejan y procesan grandes vol\u00famenes de datos, proporcionando una plataforma flexible, escalable y rentable. Su arquitectura modular permite integrar diversas herramientas, haciendo de Hadoop una elecci\u00f3n poderosa para cualquier estrategia de Big Data.</p> <p>\u00a1Empieza tu viaje en Big Data con Hadoop y desbloquea el poder de los datos masivos! \ud83d\ude80</p>"}]}